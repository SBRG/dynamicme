{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Toy Radix Lagrangean decomposition validation.\n",
    "# Guaranteed primal recovery via branch and bound."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- Obviously, full space solution still gets a better incumbent if solved to small enough gap.\n",
    "- LB for LP relaxation is the same for decomposition, obviously.\n",
    "- Decomposition gets better integer LB sooner\n",
    "- Incorporate branching strategies and heuristics from full space approach to recover better feasible primal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#OBJECTIVE    = 'minsse'\n",
    "OBJECTIVE    = 'minerr'\n",
    "REG_WEIGHT   = 0. #1e-4\n",
    "MAX_NONZERO  = None #48*2\n",
    "PREVENT_ZERO = True\n",
    "POWERS       = [-1,0,1]\n",
    "TWO_PHASE    = True\n",
    "SIMPLE_MM    = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "if SIMPLE_MM:\n",
    "    BASE_MODEL_FILE = '/home/laurence/ME/models/e_coli_core_mm_simple.json'\n",
    "else:\n",
    "    BASE_MODEL_FILE = '/home/laurence/ME/models/e_coli_core_mm.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "BASE_MODEL_FILE = '/home/laurence/ME/models/e_coli_core_pc.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from gurobipy import *\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "#pd.set_option('display.max_colwidth', -1)\n",
    "%matplotlib inline\n",
    "\n",
    "from cobra.io import load_json_model\n",
    "from six import iteritems\n",
    "import numpy as np\n",
    "import cobra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ijomc = load_json_model(BASE_MODEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.873921506968\n"
     ]
    }
   ],
   "source": [
    "ijomc.optimize()\n",
    "mu_crowd0 = ijomc.reactions.BIOMASS_Ecoli_core_w_GAM.x\n",
    "print(mu_crowd0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_meas = pd.read_csv('/home/laurence/ME/data/dynamicME/beg/growth_meas.csv')\n",
    "\n",
    "ex_rxns = [r for r in df_meas.ex_rxn.unique() if ijomc.reactions.has_id(r)]\n",
    "df_meas = df_meas[ df_meas.ex_rxn.isin(ex_rxns)]\n",
    "conds = df_meas.substrate.unique()\n",
    "\n",
    "#N_CONDS = len(conds)\n",
    "#N_CONDS = ['succinate','malate']\n",
    "#N_CONDS = ['glucose','acetate']\n",
    "N_CONDS = ['glucose','acetate','fructose']\n",
    "\n",
    "df_conds = pd.DataFrame([{'cond':r['substrate'], 'rxn':ex_rxn, 'lb':-10 if r['ex_rxn']==ex_rxn else 0, 'ub':1000., 'obj':0.} for i,r in df_meas.iterrows() for ex_rxn in ex_rxns])\n",
    "\n",
    "if hasattr(N_CONDS,'__iter__'):\n",
    "    df_conds = df_conds[ df_conds.cond.isin(N_CONDS)]\n",
    "    N_CONDS = len(N_CONDS)\n",
    "else:\n",
    "    if N_CONDS==1:\n",
    "        df_conds = df_conds[ df_conds.cond=='acetate']\n",
    "    elif N_CONDS<=3:\n",
    "        df_conds = df_conds[ df_conds.cond.isin(['glucose','acetate','succinate'][0:N_CONDS])]\n",
    "    else:\n",
    "        df_conds = df_conds[ df_conds.cond.isin(conds[0:N_CONDS])]\n",
    "\n",
    "df_conds.loc[ (df_conds.cond=='acetate') & (df_conds.rxn=='EX_ac_e'), 'lb'] = -20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sol_to_kdict(sol_final):\n",
    "    var_cons_dict = estk.var_cons_dict\n",
    "    powers = estk.powers\n",
    "    digits = estk.digits\n",
    "    radix  = estk.radix\n",
    "\n",
    "    kfit_dict = {}\n",
    "    for group_id, var_dict in iteritems(var_cons_dict):\n",
    "        var = var_dict[0]\n",
    "        cons = var_dict[1]\n",
    "        a0  = var_dict[0][2]\n",
    "        kfit = 0.\n",
    "        for l,pwr in enumerate(powers):\n",
    "            for k,digit in enumerate(digits):            \n",
    "                yid = 'binary_%s%s%s' % (group_id,k,l)\n",
    "                y   = sol_final[yid]\n",
    "                kfit += y*a0*radix**pwr*digit\n",
    "        kfit_dict[group_id] = kfit\n",
    "\n",
    "    kfit_changed = [(k,v, abs(v-a0)/a0) for k,v in iteritems(kfit_dict) if abs(v-a0)/a0>1e-6]\n",
    "    print('Changed keffs: %d/%d' % (len(kfit_changed), len(var_cons_dict)))\n",
    "    \n",
    "    return kfit_dict\n",
    "\n",
    "def compute_perf(kfit_dict, ijofit):\n",
    "    #----------------------------------------\n",
    "    # Starting from basal model\n",
    "    perrs = []\n",
    "    errs_fit = []\n",
    "    errs_unfit = []\n",
    "    csrcs = df_conds.cond.unique()\n",
    "    rows = []\n",
    "    for csrc in csrcs:        \n",
    "        crowding = ijofit.metabolites.crowding\n",
    "        #--------------------------------------------------\n",
    "        # Constrain to medium\n",
    "        df_condi = df_conds[ df_conds.cond==csrc]    \n",
    "        for i,row in df_condi.iterrows():\n",
    "            rid = row['rxn']\n",
    "            rxn = ijofit.reactions.get_by_id(rid)\n",
    "            rxn.lower_bound = row['lb']\n",
    "            rxn.upper_bound = row['ub']\n",
    "        # Get unfit growth rate first    \n",
    "        ijofit.optimize(solver='gurobi')\n",
    "        mu_unfiti = ijofit.reactions.BIOMASS_Ecoli_core_w_GAM.x\n",
    "\n",
    "        #--------------------------------------------------\n",
    "        # Fitted\n",
    "        for rid,kfit in iteritems(kfit_dict):\n",
    "            rxn = ijofit.reactions.get_by_id(rid)\n",
    "            rxn.add_metabolites({crowding:kfit}, combine=False)\n",
    "\n",
    "        ijofit.optimize(solver='gurobi')\n",
    "\n",
    "        mu_measi = df_meas[ df_meas.substrate==csrc].growth_rate_1_h.iloc[0]\n",
    "        mu_fiti = ijofit.reactions.BIOMASS_Ecoli_core_w_GAM.x\n",
    "\n",
    "        err0= 100*(mu_unfiti-mu_measi)/mu_measi\n",
    "        err = 100*(mu_fiti - mu_measi)/mu_measi\n",
    "        derr= 100*(abs(err)-abs(err0))/abs(err0)\n",
    "        perrs.append(err)\n",
    "        errs_unfit.append(mu_unfiti - mu_measi)\n",
    "        errs_fit.append(mu_fiti - mu_measi)\n",
    "        print('Cond=%s. mu_meas=%g. mu_sim=%g (unfit=%g, error=%.3g%%). Error=%.3g%% (%.3g%% change)' % (\n",
    "            csrc, mu_measi, mu_fiti, mu_unfiti, err0, err, derr))\n",
    "        for i,row in df_condi.iterrows():\n",
    "            rid = row['rxn']\n",
    "            rxn = ijofit.reactions.get_by_id(rid)        \n",
    "            print('\\t%s uptake=%g' % (rxn.id, rxn.x))\n",
    "\n",
    "        rows.append({'substrate':csrc, 'mu_fit':mu_fiti, 'mu_unfit':mu_unfiti, 'mu_meas':mu_measi})\n",
    "\n",
    "    perrs = np.array(perrs)\n",
    "    errs_fit = np.array(errs_fit)\n",
    "    errs_unfit = np.array(errs_unfit)\n",
    "    tot_err = sum(abs(errs_fit))\n",
    "    tot_err0 = sum(abs(errs_unfit))\n",
    "    mape = np.mean(abs(perrs))\n",
    "    mdape = np.median(abs(perrs))\n",
    "    print(\"Absolute total error: %g\"%(tot_err))\n",
    "    print(\"Total error change: %g%%\"%( 100*(tot_err-tot_err0)/tot_err0  ))\n",
    "    print(\"Absolute percent error: %g%% -- %g%%\"%(min(abs(perrs)), max(abs(perrs))))\n",
    "    print(\"Mean abs percent error = %g%%\"%(mape))\n",
    "    print(\"Median abs percent error = %g%%\"%(mdape))\n",
    "    \n",
    "    f_change = (tot_err-tot_err0)/tot_err0\n",
    "    perf_dict = {'tot_err':tot_err, 'err_change':f_change, 'mape':mape, 'mdape':mdape}    \n",
    "    df_results = pd.DataFrame(rows)\n",
    "    \n",
    "    return perf_dict, df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Make radix problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from dynamicme import decomposition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from dynamicme.estimate import RadixEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_Y = df_meas.rename(columns={'growth_rate_1_h':'output', 'substrate':'cond'})\n",
    "df_Y.loc[:,'output_id'] = 'BIOMASS_Ecoli_core_w_GAM'\n",
    "df_X = df_conds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Each Lagrange submodel should start with the optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from dynamicme.decomposition.LagrangeMaster import LagrangeMaster\n",
    "from dynamicme.decomposition.LagrangeSubmodel import LagrangeSubmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed value of parameter OutputFlag to 1\n",
      "   Prev: 0  Min: 0  Max: 1  Default: 1\n",
      "Changed value of parameter OutputFlag to 1\n",
      "   Prev: 0  Min: 0  Max: 1  Default: 1\n",
      "Changed value of parameter OutputFlag to 1\n",
      "   Prev: 0  Min: 0  Max: 1  Default: 1\n"
     ]
    }
   ],
   "source": [
    "conds = df_conds.cond.unique()\n",
    "sub_dict = {}\n",
    "for cond in conds:\n",
    "    df_Xk = df_X[ df_X.cond==cond]\n",
    "    df_Yk = df_Y[ df_Y.cond==cond]\n",
    "    estk = RadixEstimator()\n",
    "    if SIMPLE_MM:\n",
    "        cons_var_pairs = 'crowding'\n",
    "    else:\n",
    "        cons_var_pairs = [(cons, rxn) for cons in ijomc.metabolites.query('^enz_cap') for rxn in cons.reactions if rxn.id==cons.id.replace('enz_cap','e')]\n",
    "    estk.fit(ijomc, df_Xk, df_Yk, objective=OBJECTIVE, \n",
    "             fit_constraint_id = cons_var_pairs,\n",
    "             reg_weight = REG_WEIGHT, max_nonzero_binaries=MAX_NONZERO, optimize=False, powers=POWERS)\n",
    "    sub = LagrangeSubmodel(estk.stacker.model, cond, Q=estk.stacker.Q)    \n",
    "    sub_dict[cond] = sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "master = LagrangeMaster(estk.stacker.model)\n",
    "master.add_submodels(sub_dict)\n",
    "master.covered_dict = estk.covered_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for sub in sub_dict.values():\n",
    "    sub.model.Params.MIPGapAbs = 1e-3\n",
    "    sub.model.Params.MIPGap    = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# B&B to recover primal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from dynamicme.decomposition.LagrangeBB import LagrangeBB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "heuristics = ['average','parsimonious','best_rounding']\n",
    "lagrangeBB = LagrangeBB(master, heuristics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<dynamicme.decomposition.ProblemTree.ProblemNode at 0x7f5cd04392d0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lagrangeBB.tree.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "master.verbosity = 0\n",
    "lagrangeBB.verbosity = 1\n",
    "lagrangeBB.optimize(two_phase=True, feasible_methods=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Check best feasible solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sol_final = sol_master.copy()\n",
    "except:\n",
    "    sol_final = master.x_dict.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "u'binary_G6PDH2r00'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-26127967c85b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmdl0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_json_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_MODEL_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mkd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msol_to_kdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msol_final\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mperf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_perf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdl0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-d0cc275003b7>\u001b[0m in \u001b[0;36msol_to_kdict\u001b[0;34m(sol_final)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdigit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0myid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'binary_%s%s%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0my\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0msol_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0mkfit\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mradix\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpwr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdigit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mkfit_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: u'binary_G6PDH2r00'"
     ]
    }
   ],
   "source": [
    "mdl0 = load_json_model(BASE_MODEL_FILE)\n",
    "kd = sol_to_kdict(sol_final)\n",
    "perf, df_results = compute_perf(kd, mdl0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "dsplot = df_results.melt(['substrate','mu_meas'])\n",
    "dsplot.loc[dsplot.variable=='mu_fit','model'] = 'Fit'\n",
    "dsplot.loc[dsplot.variable=='mu_unfit','model'] = 'Unfit'\n",
    "df_perf = dsplot.groupby('variable').apply(lambda x: pd.Series({\n",
    "    'mdape':100*np.median(abs(x['value']-x['mu_meas'])/abs(x['mu_meas'])),\n",
    "    'sse':sum( (x['value']-x['mu_meas'])**2 ),\n",
    "    'rho':stats.spearmanr(x['mu_meas'],x['value'])[0],\n",
    "    'r':stats.pearsonr(x['mu_meas'],x['value'])[0]\n",
    "}))\n",
    "\n",
    "dsplot.variable = dsplot.variable.astype('category')\n",
    "dsplot.model = dsplot.model.astype('category')\n",
    "dsplot.variable.cat.reorder_categories(['mu_unfit','mu_fit'], inplace=True)\n",
    "g = sns.FacetGrid(dsplot, col='variable', hue='model', size=4)\n",
    "g.map(plt.plot, 'mu_meas','value', linestyle='None', marker='o', markeredgecolor='#000000', lw=0.2, markersize=8, alpha=0.75)\n",
    "for ax in g.axes.flat:\n",
    "    ax.plot([0,2],[0,2], zorder=1, color='#333333')\n",
    "    mdl  = ax.get_title().replace('variable = ','')\n",
    "    mdape= df_perf.loc[mdl].mdape\n",
    "    sse  = df_perf.loc[mdl].sse\n",
    "    r    = df_perf.loc[mdl].r\n",
    "    rho  = df_perf.loc[mdl].rho    \n",
    "    ax.set_title('%s (MdAPE=%.3g%%, SSE=%.3g)\\n(r=%.3g, rho=%.3g)'%(mdl,mdape, sse, r,rho))\n",
    "g.set_xlabels('Measured growth rate (h^{-1})')\n",
    "g.set_ylabels('Simulated growth rate (h^{-1})')\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
